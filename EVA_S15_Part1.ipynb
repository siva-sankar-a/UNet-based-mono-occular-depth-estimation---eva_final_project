{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA S15 Part1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_MAXgasGaMiehP0gCu0mV_gYuxs8-OKQ",
      "authorship_tag": "ABX9TyNWyQJuPTeNEcmcOOTtcprY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siva-sankar-a/eva_final_project/blob/master/EVA_S15_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA1n4NGtq7OB",
        "colab_type": "code",
        "outputId": "2194bf60-09ac-4d75-c165-57cfb573733e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!rm -rf DenseDepth\n",
        "!git clone https://github.com/ialhashim/DenseDepth.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DenseDepth'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Total 235 (delta 0), reused 0 (delta 0), pack-reused 235\u001b[K\n",
            "Receiving objects: 100% (235/235), 11.80 MiB | 13.74 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXRtshW1rCYi",
        "colab_type": "code",
        "outputId": "916b2082-bd84-4607-ca49-0e5a13875752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5 -O ./DenseDepth/nyu.h5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-16 14:04:08--  https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.88.147\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.88.147|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172897376 (165M) [application/h5]\n",
            "Saving to: ‘./DenseDepth/nyu.h5’\n",
            "\n",
            "./DenseDepth/nyu.h5 100%[===================>] 164.89M  71.4MB/s    in 2.3s    \n",
            "\n",
            "2020-05-16 14:04:10 (71.4 MB/s) - ‘./DenseDepth/nyu.h5’ saved [172897376/172897376]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIIZVOsBoXaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyJHPsC3PSWC",
        "colab_type": "code",
        "outputId": "f1500385-f3e6-4223-9e0f-d8b9639233f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Keras / TensorFlow\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
        "from keras.models import load_model\n",
        "from DenseDepth.layers import BilinearUpSampling2D\n",
        "from DenseDepth.utils import predict, load_images, display_images\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l45p1EBwm-tA",
        "colab_type": "code",
        "outputId": "47686be0-b156-43ae-ee92-48e337dc9041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = 'DenseDepth/nyu.h5'\n",
        "\n",
        "# Custom object needed for inference and training\n",
        "custom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': None}\n",
        "\n",
        "print('Loading model...')\n",
        "\n",
        "# Load model into GPU / CPU\n",
        "model = load_model(model, custom_objects=custom_objects, compile=False)\n",
        "\n",
        "print('\\nModel loaded ({0}).'.format(model))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "\n",
            "Model loaded (<keras.engine.training.Model object at 0x7feccb611dd8>).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHPswL1fS04a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets.utils import download_url, download_and_extract_archive\n",
        "from multiprocessing import Process\n",
        "from zipfile import ZipFile, ZIP_DEFLATED\n",
        "import os\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import urllib\n",
        "import tqdm\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldBN6zz0lpX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FgBgDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Custom class to load foreground background image dataset\n",
        "  \"\"\"\n",
        "  def __init__(self, no_of_parts=10, train_transform=None, test_transform=None, target_transform=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Constructor for foreground background image dataset\n",
        "    \"\"\"\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.ROOT_URL = 'https://eva-final-project-dataset.s3-ap-southeast-2.amazonaws.com/'\n",
        "    self.COMPRESSED_DIR = './compressed'\n",
        "    self.DATASET_DIR = './dataset'\n",
        "    self.DATASET_INFO_FILE = 'dataset_info.csv'\n",
        "    self.DATASET_FILE_PREFIX = 'dataset_'\n",
        "\n",
        "    self.no_of_parts = no_of_parts\n",
        "    self.dataset_info_file_path = os.path.join(self.DATASET_DIR, self.DATASET_INFO_FILE)\n",
        "\n",
        "    self.download_dataset()\n",
        "\n",
        "    self.df = pd.read_csv(self.dataset_info_file_path)\n",
        "\n",
        "    self.train = True\n",
        "    self.train_transform = train_transform\n",
        "    self.test_transform = test_transform\n",
        "    self.target_transform = target_transform \n",
        "\n",
        "  def download_dataset(self):\n",
        "    if not os.path.exists(self.DATASET_DIR):\n",
        "      print('Downloading dataset..')\n",
        "      os.mkdir(self.DATASET_DIR)\n",
        "      if not os.path.exists(self.COMPRESSED_DIR):\n",
        "        os.mkdir(self.COMPRESSED_DIR)\n",
        "\n",
        "      dataset_info_url = urllib.parse.urljoin(self.ROOT_URL, self.DATASET_INFO_FILE)\n",
        "      download_url(dataset_info_url, self.DATASET_DIR, self.DATASET_INFO_FILE)\n",
        "      dataset_info_url = urllib.parse.urljoin(self.ROOT_URL, self.DATASET_INFO_FILE)\n",
        "\n",
        "      processes = [Process(target=self.download_and_extract_part, args=(part_idx,)) for part_idx in range(self.no_of_parts)]\n",
        "      for process in processes:\n",
        "        process.start()\n",
        "      for process in processes:\n",
        "        process.join()\n",
        "    else:\n",
        "      print('Dataset found!')\n",
        "\n",
        "  def download_and_extract_part(self, part):\n",
        "    dataset_part_path = f'{self.DATASET_FILE_PREFIX}{part}.zip'\n",
        "    dataset_part_url = urllib.parse.urljoin(self.ROOT_URL, dataset_part_path)\n",
        "    download_and_extract_archive(dataset_part_url, self.COMPRESSED_DIR, self.DATASET_DIR)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.df)\n",
        "\n",
        "  def set_train(self):\n",
        "      self.train = True\n",
        "\n",
        "  def set_eval(self):\n",
        "      self.train = False\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        index (int): Index\n",
        "\n",
        "    Returns:\n",
        "        tuple: (image, target) where target is index of the target class.\n",
        "    \"\"\"\n",
        "    if torch.is_tensor(index):\n",
        "      index = index.tolist()\n",
        "\n",
        "    fg_bg_path = os.path.join(self.DATASET_DIR, self.df['fg_bg_paths'].iloc[index])\n",
        "    mask_path = os.path.join(self.DATASET_DIR, self.df['mask_paths'].iloc[index])\n",
        "\n",
        "    # print(index, fg_bg_path, mask_path)\n",
        "    \n",
        "    # fg_bg_img = cv2.imread(fg_bg_path)\n",
        "    # mask_img = cv2.imread(mask_path)\n",
        "    \n",
        "    file_name = os.path.basename(fg_bg_path)\n",
        "\n",
        "    # print(fg_bg_img.shape, mask_img.shape)\n",
        "\n",
        "    if self.train:\n",
        "      if self.train_transform:\n",
        "        augmented = self.train_transform(image=fg_bg_img)\n",
        "        fg_bg_img = augmented['image']\n",
        "    else:\n",
        "      if self.test_transform:\n",
        "        augmented = self.test_transform(image=fg_bg_img)\n",
        "        fg_bg_img = augmented['image']\n",
        "\n",
        "    if self.target_transform is not None:\n",
        "      mask_img = self.target_transform(mask_img)\n",
        "\n",
        "    return { 'index': index, 'file_name': file_name, 'fg_bg_path': fg_bg_path } # 'fg_bg': fg_bg_img, 'mask': mask_img }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJxAhUjOheJ",
        "colab_type": "code",
        "outputId": "b2d27d32-efab-454d-d113-d1cdeebf1a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset = FgBgDataset()\n",
        "batch_size = 8\n",
        "use_cuda = True\n",
        "dataloader_args = dict(shuffle=False, batch_size=batch_size, num_workers=4, pin_memory=True) if use_cuda else dict(shuffle=True, batch_size=batch_size)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, **dataloader_args, drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset found!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUNWQWBpVLpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('dataset/depth'):\n",
        "  os.mkdir('dataset/depth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ichk_JkN_AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_depth(model, device, data_loader):\n",
        "    compression_level = 40\n",
        "    pbar = tqdm.tqdm(data_loader)\n",
        "    train_len = len(data_loader.dataset)\n",
        "    data_loader.dataset.df['depth_map_paths'] = ''\n",
        "\n",
        "    for batch_idx, sample_batch in enumerate(pbar):\n",
        "        \n",
        "        inputs = load_images(sample_batch['fg_bg_path'])\n",
        "        outputs = predict(model, inputs, minDepth=1, maxDepth=300, batch_size=batch_size)\n",
        "\n",
        "        depth_map_paths = []\n",
        "\n",
        "        for idx, depth_map in enumerate(outputs):\n",
        "          depth_map = 1 - (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
        "          depth_map *= 255\n",
        "          depth_map.astype(np.uint8)\n",
        "          depth_map_path = os.path.join('dataset', 'depth', sample_batch['file_name'][idx])\n",
        "          cv2.imwrite(depth_map_path, depth_map, [int(cv2.IMWRITE_JPEG_QUALITY), compression_level])\n",
        "          depth_map_paths.append(depth_map_path)\n",
        "\n",
        "        data_loader.dataset.df.loc[sample_batch['index'], 'depth_map_paths'] = depth_map_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "352aDXU7khAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tqdm.tqdm._instances.clear()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypmyFjOs5UPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf dataset/depth/\n",
        "!mkdir dataset/depth/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGcsgEQceLK8",
        "colab_type": "code",
        "outputId": "1a8e0051-91f7-4fd3-f50e-1e83d41c30a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "get_depth(model, 'cuda', data_loader)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [2:08:36<00:00,  1.54s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnXdDlDimA1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "23ab194d-293d-4f17-a01e-ff4a36b6851a"
      },
      "source": [
        "data_loader.dataset.df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fg_bg_paths</th>\n",
              "      <th>mask_paths</th>\n",
              "      <th>part</th>\n",
              "      <th>depth_map_paths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./fg_bg/img_00112256.jpg</td>\n",
              "      <td>./mask/img_00112256.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>./depth/img_00112256.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./fg_bg/img_00081760.jpg</td>\n",
              "      <td>./mask/img_00081760.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>./depth/img_00081760.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./fg_bg/img_00164049.jpg</td>\n",
              "      <td>./mask/img_00164049.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>./depth/img_00164049.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./fg_bg/img_00081730.jpg</td>\n",
              "      <td>./mask/img_00081730.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>./depth/img_00081730.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./fg_bg/img_00067725.jpg</td>\n",
              "      <td>./mask/img_00067725.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>./depth/img_00067725.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                fg_bg_paths  ...           depth_map_paths\n",
              "0  ./fg_bg/img_00112256.jpg  ...  ./depth/img_00112256.jpg\n",
              "1  ./fg_bg/img_00081760.jpg  ...  ./depth/img_00081760.jpg\n",
              "2  ./fg_bg/img_00164049.jpg  ...  ./depth/img_00164049.jpg\n",
              "3  ./fg_bg/img_00081730.jpg  ...  ./depth/img_00081730.jpg\n",
              "4  ./fg_bg/img_00067725.jpg  ...  ./depth/img_00067725.jpg\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XPpR84CnaKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader.dataset.df['depth_map_paths'] = data_loader.dataset.df['depth_map_paths'].str.replace('dataset', '.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJcqrHCBmj9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_parts = 10\n",
        "_sample_dfs = np.array_split(data_loader.dataset.df, n_parts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDNRhLKXmtv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, _df in enumerate(_sample_dfs):\n",
        "    data_loader.dataset.df.loc[_df.index, 'part'] = idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_Dih0PUm3ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader.dataset.df.to_csv('dataset_info.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daBNGKqH38yn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "457a233c-8b2a-44fc-b132-2e232f271e9b"
      },
      "source": [
        "!ls -al dataset/depth/ | wc -l"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmSH3zfTnDnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f07a1c7d-3cda-4aca-ac72-c16b126eb121"
      },
      "source": [
        "for idx, _df in enumerate(_sample_dfs):\n",
        "    with ZipFile(f'dataset_{idx}.zip', 'w', ZIP_DEFLATED) as dataset:\n",
        "        pbar = tqdm.tqdm(_df.iterrows())\n",
        "        for idx, row in pbar:\n",
        "          dataset.write(os.path.join('dataset', row['mask_paths']), row['mask_paths'])\n",
        "          dataset.write(os.path.join('dataset', row['fg_bg_paths']), row['fg_bg_paths'])\n",
        "          dataset.write(os.path.join('dataset', row['depth_map_paths']), row['depth_map_paths'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000it [00:25, 157.19it/s]\n",
            "4000it [00:35, 112.38it/s]\n",
            "4000it [00:35, 113.08it/s]\n",
            "4000it [00:35, 111.59it/s]\n",
            "4000it [00:36, 111.01it/s]\n",
            "4000it [00:34, 114.64it/s]\n",
            "4000it [00:35, 114.20it/s]\n",
            "4000it [00:35, 114.24it/s]\n",
            "4000it [00:34, 114.91it/s]\n",
            "4000it [00:34, 117.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl1k1_OhqGxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "c29c3135-6c2c-41ec-a35b-6d6dad7453a7"
      },
      "source": [
        "!stat dataset_0.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  File: dataset_0.zip\n",
            "  Size: 516232134 \tBlocks: 1008280    IO Block: 4096   regular file\n",
            "Device: 32h/50d\tInode: 2764023     Links: 1\n",
            "Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\n",
            "Access: 2020-05-16 19:08:24.001851764 +0000\n",
            "Modify: 2020-05-16 19:13:43.692157556 +0000\n",
            "Change: 2020-05-16 19:13:43.692157556 +0000\n",
            " Birth: -\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I8L2ONQrJTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import boto3\n",
        "from botocore.exceptions import ClientError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heb_iXe6rPyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = boto3.Session(\n",
        "    aws_access_key_id='***************',\n",
        "    aws_secret_access_key='*****************************',\n",
        ")\n",
        "s3 = session.resource('s3')\n",
        "bucket = s3.Bucket('eva-final-project-dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le6L9G9lvl3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upload_file(bucket, file_path, object_name):\n",
        "  if object_name is None:\n",
        "      object_name = file_path\n",
        "\n",
        "  try:\n",
        "      response = bucket.upload_file(file_path, object_name)\n",
        "  except ClientError as e:\n",
        "      logging.error(e)\n",
        "      return False\n",
        "  return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SMh6e4Evob9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6a75a37-9258-4363-f6e9-e1c0b6530fd7"
      },
      "source": [
        "upload_file(bucket, 'dataset_info.csv', 'dataset_info.csv')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLSxqLjj82Ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9a47ba31-8ccb-4216-82d4-c32ecf413502"
      },
      "source": [
        "for idx in range(10):\n",
        "  file_path = f'dataset_{idx}.zip'\n",
        "  if upload_file(bucket, file_path, file_path):\n",
        "    print(f'{file_path} success!!!')\n",
        "  else:\n",
        "    print(f'{file_path} failed!!!')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_0.zip success!!!\n",
            "dataset_1.zip success!!!\n",
            "dataset_2.zip success!!!\n",
            "dataset_3.zip success!!!\n",
            "dataset_4.zip success!!!\n",
            "dataset_5.zip success!!!\n",
            "dataset_6.zip success!!!\n",
            "dataset_7.zip success!!!\n",
            "dataset_8.zip success!!!\n",
            "dataset_9.zip success!!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
